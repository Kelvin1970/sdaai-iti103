{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BQFvzAM0OvF5"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/nyp-sit/sdaai-staff-repo/blob/master/iti103/session-7(imbalanced-data)/Oversampling(Solution).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\" align=\"left\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DnqURdKXOvF9"
   },
   "source": [
    "# Dealing with Imbalanced Data Set\n",
    "\n",
    "Welcome to the programming exercise. This is part of the series of exercises to help you acquire skills in different techniques to fine-tune your model.\n",
    "\n",
    "**You will learn:**\n",
    "- how to use oversampling correctly for imbalanced data set\n",
    "- how to perform oversampling using K-folds\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7RwnjO0pOvF-"
   },
   "source": [
    "## Oversampling\n",
    "\n",
    "In this exercise, we will use a highly imbalanced data set from Lending Club that consists of data for both 'bad' and 'good' loans to illustrate the proper way of oversampling. The focus of this exercise is not to produce accurate model but to illustrate the 'effect' that wrong oversampling has on the model performance. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kLhPfND5OvF-"
   },
   "source": [
    "### 1. Import the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "id": "1155FtcFOvF_",
    "outputId": "73f5033a-d466-4420-89e2-d6dd4d495373"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/externals/six.py:31: DeprecationWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
      "  \"(https://pypi.org/project/six/).\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', module='sklearn')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import urllib.request\n",
    "import shutil\n",
    "import zipfile\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "C4uzbQmnOvGE"
   },
   "source": [
    "### 2. Get the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OKm5pvtTOvGF"
   },
   "outputs": [],
   "source": [
    "url = 'https://github.com/nyp-sit/data/raw/master/lending-club-data.csv.zip'\n",
    "zip_file = \"lending_club-data.csv.zip\"\n",
    "\n",
    "# download the zip file and copy to a file 'lending-club-data.csv.zip'\n",
    "with urllib.request.urlopen(url) as response, open(zip_file, 'wb') as out_file:\n",
    "    shutil.copyfileobj(response, out_file)\n",
    "    \n",
    "# unzip the file to a folder 'data'\n",
    "data_file = 'lending_club_data.csv'\n",
    "\n",
    "with zipfile.ZipFile(zip_file,\"r\") as zip_ref:\n",
    "    zip_ref.extractall('data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RUjfEldbOvGI"
   },
   "source": [
    "### 3. Some data exploratory analysis\n",
    "\n",
    "Here we are trying to find out some information about the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "id": "_KUTDi-oOvGJ",
    "outputId": "0e9b7386-e409-4ecb-e479-040bcd3eb099"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2718: DtypeWarning: Columns (19,47) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('data/lending-club-data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "U1PMtr7wOvGP"
   },
   "source": [
    "Let us just find out about different features and their data types. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1283
    },
    "colab_type": "code",
    "id": "_KphBoylOvGQ",
    "outputId": "626ba1d6-0403-4a2d-b48c-f82b4eab4b70"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 122607 entries, 0 to 122606\n",
      "Data columns (total 68 columns):\n",
      "id                             122607 non-null int64\n",
      "member_id                      122607 non-null int64\n",
      "loan_amnt                      122607 non-null int64\n",
      "funded_amnt                    122607 non-null int64\n",
      "funded_amnt_inv                122607 non-null int64\n",
      "term                           122607 non-null object\n",
      "int_rate                       122607 non-null float64\n",
      "installment                    122607 non-null float64\n",
      "grade                          122607 non-null object\n",
      "sub_grade                      122607 non-null object\n",
      "emp_title                      115767 non-null object\n",
      "emp_length                     118516 non-null object\n",
      "home_ownership                 122607 non-null object\n",
      "annual_inc                     122603 non-null float64\n",
      "is_inc_v                       122607 non-null object\n",
      "issue_d                        122607 non-null object\n",
      "loan_status                    122607 non-null object\n",
      "pymnt_plan                     122607 non-null object\n",
      "url                            122607 non-null object\n",
      "desc                           60705 non-null object\n",
      "purpose                        122607 non-null object\n",
      "title                          122596 non-null object\n",
      "zip_code                       122607 non-null object\n",
      "addr_state                     122607 non-null object\n",
      "dti                            122607 non-null float64\n",
      "delinq_2yrs                    122578 non-null float64\n",
      "earliest_cr_line               122578 non-null object\n",
      "inq_last_6mths                 122578 non-null float64\n",
      "mths_since_last_delinq         50500 non-null float64\n",
      "mths_since_last_record         12531 non-null float64\n",
      "open_acc                       122578 non-null float64\n",
      "pub_rec                        122578 non-null float64\n",
      "revol_bal                      122607 non-null int64\n",
      "revol_util                     122607 non-null float64\n",
      "total_acc                      122578 non-null float64\n",
      "initial_list_status            122607 non-null object\n",
      "out_prncp                      122607 non-null float64\n",
      "out_prncp_inv                  122607 non-null float64\n",
      "total_pymnt                    122607 non-null float64\n",
      "total_pymnt_inv                122607 non-null float64\n",
      "total_rec_prncp                122607 non-null float64\n",
      "total_rec_int                  122607 non-null float64\n",
      "total_rec_late_fee             122607 non-null float64\n",
      "recoveries                     122607 non-null float64\n",
      "collection_recovery_fee        122607 non-null float64\n",
      "last_pymnt_d                   122271 non-null object\n",
      "last_pymnt_amnt                122607 non-null float64\n",
      "next_pymnt_d                   2907 non-null object\n",
      "last_credit_pull_d             122601 non-null object\n",
      "collections_12_mths_ex_med     122462 non-null float64\n",
      "mths_since_last_major_derog    15460 non-null float64\n",
      "policy_code                    122607 non-null int64\n",
      "not_compliant                  122607 non-null int64\n",
      "status                         122607 non-null object\n",
      "inactive_loans                 122607 non-null int64\n",
      "bad_loans                      122607 non-null int64\n",
      "emp_length_num                 122607 non-null int64\n",
      "grade_num                      122607 non-null int64\n",
      "sub_grade_num                  122607 non-null float64\n",
      "delinq_2yrs_zero               122578 non-null float64\n",
      "pub_rec_zero                   122578 non-null float64\n",
      "collections_12_mths_zero       122462 non-null float64\n",
      "short_emp                      122607 non-null int64\n",
      "payment_inc_ratio              122603 non-null float64\n",
      "final_d                        122607 non-null object\n",
      "last_delinq_none               122607 non-null int64\n",
      "last_record_none               122607 non-null int64\n",
      "last_major_derog_none          122607 non-null int64\n",
      "dtypes: float64(29), int64(16), object(23)\n",
      "memory usage: 63.6+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kGorNXkCOvGU"
   },
   "source": [
    "In this exercise, we are trying to predict if a member will default on his loan or not. So we will be using the feature column 'bad_loans' as the label for our classification task. If the value of `bad_loan` is 1, it means it is a default (or bad loan), otherwise, it is 0.  \n",
    "\n",
    "***Exercise:***\n",
    "\n",
    "Find out how many samples in the data set is bad loans and how many are not. \n",
    "\n",
    "Hint: `value_counts()` in [pandas](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.value_counts.html) give you the count of unique values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "colab_type": "code",
    "id": "LxAwMqOLOvGV",
    "outputId": "f121e501-e098-4d29-db9f-7a72340a169b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    99457\n",
       "1    23150\n",
       "Name: bad_loans, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### START CODE HERE ###\n",
    "\n",
    "df.bad_loans.value_counts()\n",
    "\n",
    "### END CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KbTZ3HYROvGZ"
   },
   "source": [
    "Is the data set imbalanced? Clearly we have a lot of more good loans than bad loans (around 4 times more)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Q-699YfGOvGZ"
   },
   "source": [
    "### 4. Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SqFZxW3POvGa"
   },
   "source": [
    "There are quite a lot of features in this data set but we are just going to use a few, just for demonstration purpose (as we are not really interested in actual performance of our model)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GiB1_iyKOvGb"
   },
   "outputs": [],
   "source": [
    "features = ['grade', 'home_ownership','emp_length_num', 'sub_grade','short_emp',\n",
    "            'dti', 'term', 'purpose', 'int_rate', 'last_delinq_none', 'last_major_derog_none',\n",
    "            'revol_util', 'total_rec_late_fee', 'payment_inc_ratio', 'bad_loans']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ThOEfOuTOvGe"
   },
   "source": [
    "***Exercise:*** \n",
    "\n",
    "Create a data frame that consist of the subset of features listed above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QcD4E6QMOvGf"
   },
   "outputs": [],
   "source": [
    "### START CODE HERE ### \n",
    "\n",
    "df = df[features]\n",
    "\n",
    "### END CODE HERE ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 364
    },
    "colab_type": "code",
    "id": "3I0zJTN0OvGi",
    "outputId": "cc071b38-d5c9-440e-853a-de08080a2e0a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 122607 entries, 0 to 122606\n",
      "Data columns (total 15 columns):\n",
      "grade                    122607 non-null object\n",
      "home_ownership           122607 non-null object\n",
      "emp_length_num           122607 non-null int64\n",
      "sub_grade                122607 non-null object\n",
      "short_emp                122607 non-null int64\n",
      "dti                      122607 non-null float64\n",
      "term                     122607 non-null object\n",
      "purpose                  122607 non-null object\n",
      "int_rate                 122607 non-null float64\n",
      "last_delinq_none         122607 non-null int64\n",
      "last_major_derog_none    122607 non-null int64\n",
      "revol_util               122607 non-null float64\n",
      "total_rec_late_fee       122607 non-null float64\n",
      "payment_inc_ratio        122603 non-null float64\n",
      "bad_loans                122607 non-null int64\n",
      "dtypes: float64(5), int64(5), object(5)\n",
      "memory usage: 14.0+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "54vsiwgBOvGm"
   },
   "source": [
    "Notice that `payment_inc_ratio` has some null values, and since it is only a small number, just remove the rows that have null values for `payment_inc_ratio`.\n",
    "\n",
    "***Exercise***\n",
    "\n",
    "Create a new data frame that have the rows that contains null values for `payment_inc_ratio` removed. \n",
    "\n",
    "Hint: `~df.payment_inc_ratio.isnull()` will give return a series of boolean(true/false mask) to indicate which rows of payment_inc_ration is **NOT** null. Construct the new data frame using `df[boolean mask]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "o2LnIJIEOvGn"
   },
   "outputs": [],
   "source": [
    "### START CODE HERE ###\n",
    "\n",
    "loans_df = None \n",
    "loans_df = df[~df.payment_inc_ratio.isnull()]\n",
    "\n",
    "#### END CODE HERE ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 364
    },
    "colab_type": "code",
    "id": "-kvTJH5-OvGq",
    "outputId": "d9301060-c894-4386-a3c3-d7908ff8c8d5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 122603 entries, 0 to 122606\n",
      "Data columns (total 15 columns):\n",
      "grade                    122603 non-null object\n",
      "home_ownership           122603 non-null object\n",
      "emp_length_num           122603 non-null int64\n",
      "sub_grade                122603 non-null object\n",
      "short_emp                122603 non-null int64\n",
      "dti                      122603 non-null float64\n",
      "term                     122603 non-null object\n",
      "purpose                  122603 non-null object\n",
      "int_rate                 122603 non-null float64\n",
      "last_delinq_none         122603 non-null int64\n",
      "last_major_derog_none    122603 non-null int64\n",
      "revol_util               122603 non-null float64\n",
      "total_rec_late_fee       122603 non-null float64\n",
      "payment_inc_ratio        122603 non-null float64\n",
      "bad_loans                122603 non-null int64\n",
      "dtypes: float64(5), int64(5), object(5)\n",
      "memory usage: 15.0+ MB\n"
     ]
    }
   ],
   "source": [
    "loans_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mdYkuMW2OvGs"
   },
   "source": [
    "***Exercise:*** \n",
    "\n",
    "Encode the categorical columns (dtype=object). You can use the convenience method `get_dummies()` provide by [pandas](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.get_dummies.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LtXWlMJuOvGt"
   },
   "outputs": [],
   "source": [
    "### START CODE HERE ###\n",
    "\n",
    "loans_encoded = pd.get_dummies(loans_df)\n",
    "\n",
    "### END CODE HERE ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1317
    },
    "colab_type": "code",
    "id": "Ee_Jj-lfOvGv",
    "outputId": "f434ba18-c5be-443e-a81d-f7c3de9cdac8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 122603 entries, 0 to 122606\n",
      "Data columns (total 70 columns):\n",
      "emp_length_num                122603 non-null int64\n",
      "short_emp                     122603 non-null int64\n",
      "dti                           122603 non-null float64\n",
      "int_rate                      122603 non-null float64\n",
      "last_delinq_none              122603 non-null int64\n",
      "last_major_derog_none         122603 non-null int64\n",
      "revol_util                    122603 non-null float64\n",
      "total_rec_late_fee            122603 non-null float64\n",
      "payment_inc_ratio             122603 non-null float64\n",
      "bad_loans                     122603 non-null int64\n",
      "grade_A                       122603 non-null uint8\n",
      "grade_B                       122603 non-null uint8\n",
      "grade_C                       122603 non-null uint8\n",
      "grade_D                       122603 non-null uint8\n",
      "grade_E                       122603 non-null uint8\n",
      "grade_F                       122603 non-null uint8\n",
      "grade_G                       122603 non-null uint8\n",
      "home_ownership_MORTGAGE       122603 non-null uint8\n",
      "home_ownership_OTHER          122603 non-null uint8\n",
      "home_ownership_OWN            122603 non-null uint8\n",
      "home_ownership_RENT           122603 non-null uint8\n",
      "sub_grade_A1                  122603 non-null uint8\n",
      "sub_grade_A2                  122603 non-null uint8\n",
      "sub_grade_A3                  122603 non-null uint8\n",
      "sub_grade_A4                  122603 non-null uint8\n",
      "sub_grade_A5                  122603 non-null uint8\n",
      "sub_grade_B1                  122603 non-null uint8\n",
      "sub_grade_B2                  122603 non-null uint8\n",
      "sub_grade_B3                  122603 non-null uint8\n",
      "sub_grade_B4                  122603 non-null uint8\n",
      "sub_grade_B5                  122603 non-null uint8\n",
      "sub_grade_C1                  122603 non-null uint8\n",
      "sub_grade_C2                  122603 non-null uint8\n",
      "sub_grade_C3                  122603 non-null uint8\n",
      "sub_grade_C4                  122603 non-null uint8\n",
      "sub_grade_C5                  122603 non-null uint8\n",
      "sub_grade_D1                  122603 non-null uint8\n",
      "sub_grade_D2                  122603 non-null uint8\n",
      "sub_grade_D3                  122603 non-null uint8\n",
      "sub_grade_D4                  122603 non-null uint8\n",
      "sub_grade_D5                  122603 non-null uint8\n",
      "sub_grade_E1                  122603 non-null uint8\n",
      "sub_grade_E2                  122603 non-null uint8\n",
      "sub_grade_E3                  122603 non-null uint8\n",
      "sub_grade_E4                  122603 non-null uint8\n",
      "sub_grade_E5                  122603 non-null uint8\n",
      "sub_grade_F1                  122603 non-null uint8\n",
      "sub_grade_F2                  122603 non-null uint8\n",
      "sub_grade_F3                  122603 non-null uint8\n",
      "sub_grade_F4                  122603 non-null uint8\n",
      "sub_grade_F5                  122603 non-null uint8\n",
      "sub_grade_G1                  122603 non-null uint8\n",
      "sub_grade_G2                  122603 non-null uint8\n",
      "sub_grade_G3                  122603 non-null uint8\n",
      "sub_grade_G4                  122603 non-null uint8\n",
      "sub_grade_G5                  122603 non-null uint8\n",
      "term_ 36 months               122603 non-null uint8\n",
      "term_ 60 months               122603 non-null uint8\n",
      "purpose_car                   122603 non-null uint8\n",
      "purpose_credit_card           122603 non-null uint8\n",
      "purpose_debt_consolidation    122603 non-null uint8\n",
      "purpose_home_improvement      122603 non-null uint8\n",
      "purpose_house                 122603 non-null uint8\n",
      "purpose_major_purchase        122603 non-null uint8\n",
      "purpose_medical               122603 non-null uint8\n",
      "purpose_moving                122603 non-null uint8\n",
      "purpose_other                 122603 non-null uint8\n",
      "purpose_small_business        122603 non-null uint8\n",
      "purpose_vacation              122603 non-null uint8\n",
      "purpose_wedding               122603 non-null uint8\n",
      "dtypes: float64(5), int64(5), uint8(60)\n",
      "memory usage: 17.3 MB\n"
     ]
    }
   ],
   "source": [
    "loans_encoded.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pplOyf8XOvGz"
   },
   "source": [
    "### 5. Split the data set into train and test set\n",
    "\n",
    "***Exercise:*** \n",
    "\n",
    "Separate the features and the label.  \n",
    "\n",
    "Hint: use `df.drop()` and specify `axis=1` to remove a particular column in dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HV7UrEgrOvG0"
   },
   "outputs": [],
   "source": [
    "### START CODE HERE ###\n",
    "\n",
    "# X_df contains all the feature columns and y_df contains only the label, i.e. bad_loans column\n",
    "\n",
    "X_df = loans_encoded.drop(['bad_loans'], axis=1)\n",
    "y_df = loans_encoded['bad_loans']\n",
    "\n",
    "### END CODE HERE ### \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_df, y_df, \n",
    "                                                    test_size = .1, \n",
    "                                                    stratify = y_df,\n",
    "                                                    random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "colab_type": "code",
    "id": "CeEr2-jBOvG4",
    "outputId": "48ecb29f-207c-4d15-fc4b-aa19b74dd211"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    89507\n",
      "1    20835\n",
      "Name: bad_loans, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(y_train.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ms9xSxclOvG-"
   },
   "source": [
    "### 6. The ***wrong*** way to oversample ###\n",
    "\n",
    "With the training data created, we can oversample the minority class (the bad_loan = 1). In this exercise, we will use the SMOTE (from the [imblearn](https://imbalanced-learn.readthedocs.io/en/stable/index.html) library) to create synthetic samples of the minority class. \n",
    "\n",
    "After upsampling to a class ratio of 1.0 (i.e. 1 to 1 ratio between positive and negative classes) you should have a balanced dataset. In most cases, there’s often no need to balance the classes totally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "09afPcnaOvG_"
   },
   "outputs": [],
   "source": [
    "# Set sampling_strategy='minority' to oversample only the minority class \n",
    "\n",
    "sm = SMOTE(sampling_strategy='minority',random_state=42)\n",
    "X_upsample, y_upsample = sm.fit_sample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EYewJVUYOvHB"
   },
   "source": [
    "Now you see that the samples are totally balanced.  `np.bincount()` counts number of occurrences of each value in array of non-negative ints.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "AzcmiL-YOvHC",
    "outputId": "779deb33-eb62-4e85-c9a0-ec73bd9033be"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[89507 89507]\n"
     ]
    }
   ],
   "source": [
    "print(np.bincount(y_upsample))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kxd1sYiJOvHG"
   },
   "source": [
    "Now let us split the up-sampled training data set into training and validation set.\n",
    "\n",
    "***Note:***\n",
    "\n",
    "It might be a bit confusing as we talk about training sets. We have our original data set, `X` and we split into `X_train` and `X_test`.  We up-sample the `X_train` to get `X_upsample`. And then from the `X_upsample`, we further set aside a train set and validation set, which we call: `X_train_final`, and `X_val_final` to differentiate from the earlier `X_train` and `X_upsample`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "M8ewnQ5JOvHI"
   },
   "outputs": [],
   "source": [
    "#now split into cross validation\n",
    "\n",
    "X_train_final, X_val_final, y_train_final, y_val_final = train_test_split(X_upsample, y_upsample, \n",
    "                                                                          test_size=.1, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dyl14DBIOvHL"
   },
   "source": [
    "We then train a classifier and look at the performance of the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "colab_type": "code",
    "id": "P5LXxQ5IOvHM",
    "outputId": "47e41a81-7a30-450e-9bd6-38eefd28ab29"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=25,\n",
       "                       n_jobs=None, oob_score=False, random_state=42, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 19,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_rf = RandomForestClassifier(n_estimators=25, random_state=42)\n",
    "clf_rf.fit(X_train_final, y_train_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ANosUgZNOvHS"
   },
   "source": [
    "As we are interested in knowing how well our model is in picking out 'bad loan', it would be useful to look at the recall score of the model. \n",
    "\n",
    "***Exercise:*** \n",
    "\n",
    "Find the accuracy and the recall of the model on the validation set, i.e. `X_val_final`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "FYGhDwZDOvHS",
    "outputId": "98a31178-8ea0-4f95-c508-3276a79114c8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 0.8788403530331806\n",
      "recall = 0.8043982760526025\n"
     ]
    }
   ],
   "source": [
    "### START THE CODE ### \n",
    "y_val_final_pred = clf_rf.predict(X_val_final)\n",
    "\n",
    "accuracy = accuracy_score(y_val_final, y_val_final_pred)\n",
    "recall = recall_score(y_val_final, y_val_final_pred)\n",
    "\n",
    "### END THE CODE ### \n",
    "\n",
    "print('accuracy = {}'.format(accuracy))\n",
    "print('recall = {}'.format(recall))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9KfgDk-OOvHU"
   },
   "source": [
    "Expected output: \n",
    "\n",
    "<img src='https://github.com/nyp-sit/sdaai-staff-repo/blob/master/iti103/session-7(imbalanced-data)/images/acc_recall_score1.png?raw=1' />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IdknGvRgOvHV"
   },
   "source": [
    "80% recall, that is pretty good! It means the model correctly identified 80% of the total bad loans. But is this actually representative of how the model will perform? To find out, let's test the model on the test set we created initially.\n",
    "\n",
    "***Exercise:*** \n",
    "\n",
    "Find the accuracy and the recall of the model on the test set, i.e. `X_test`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "au3pbo7OOvHV",
    "outputId": "8fdc7e7c-0e13-4303-e3c6-688661db936d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 0.8045836391811435\n",
      "recall = 0.14514038876889848\n"
     ]
    }
   ],
   "source": [
    "### START THE CODE ### \n",
    "y_test_pred = clf_rf.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_test_pred)\n",
    "recall = recall_score(y_test, y_test_pred)\n",
    "\n",
    "### END THE CODE ### \n",
    "\n",
    "print('accuracy = {}'.format(accuracy))\n",
    "print('recall = {}'.format(recall))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9RPUZuoFOvHa"
   },
   "source": [
    "Expected output: \n",
    "\n",
    "<img src='https://github.com/nyp-sit/sdaai-staff-repo/blob/master/iti103/session-7(imbalanced-data)/images/acc_recall_score2.png?raw=1' />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "INAtz44QOvHa"
   },
   "source": [
    "Only 80% accuracy and 15% recall on the test data. That’s disappointing! What has happened?\n",
    "\n",
    "By oversampling before splitting into training and validation datasets, we “leaked” information from the validation set into the training of the model (refer to your lecture for more details)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "p-fkAmtpOvHb"
   },
   "source": [
    "### 7. The ***right way*** to oversample\n",
    "\n",
    "So, let do it the right way and see what happens. This time round, we will oversample the training set and not the train + validation set. Oversampling is done after we set aside the validation set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dcdqazCuOvHc"
   },
   "outputs": [],
   "source": [
    "## Here we set aside a cross validation set first \n",
    "\n",
    "X_train_proper,  X_val_proper, y_train_proper, y_val_proper = train_test_split(X_train, y_train, test_size=.1, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "da-q1LuFOvHe"
   },
   "source": [
    "Now as before, we use SMOTE to oversample the minority class, but this time we only oversample from the train set.  \n",
    "\n",
    "***Note:***\n",
    "\n",
    "It might be a bit confusing as we talk about training sets. We have our original data set, `X` and we split into `X_train` and `X_test`.  And then from the `X_train`, we further set aside a train set and validation set, which we call: `X_train_proper`, and `X_val_proper` to differentiate from the earlier `X_train`. \n",
    "\n",
    "***Exercise:***\n",
    "\n",
    "Use SMOTE (as before) to over-sample the `X_train_proper`. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KM6n8hrKOvHf"
   },
   "outputs": [],
   "source": [
    "### START CODE HERE ###\n",
    "\n",
    "sm = SMOTE(sampling_strategy='minority',random_state=42) \n",
    "X_train_proper_upsampled, y_train_proper_upsampled = sm.fit_sample(X_train_proper, y_train_proper)\n",
    "\n",
    "### END CODE HERE ### "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "spryBAWSOvHh"
   },
   "source": [
    "We then train a classifier and look at the performance of the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "colab_type": "code",
    "id": "XixuEHXpOvHi",
    "outputId": "d8aa3c1c-49af-4e70-f2a2-b5e6f1afe685"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=25,\n",
       "                       n_jobs=None, oob_score=False, random_state=42, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 24,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_rf = RandomForestClassifier(n_estimators=25, random_state=42)\n",
    "clf_rf.fit(X_train_proper_upsampled, y_train_proper_upsampled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WD-dU3A1OvHl"
   },
   "source": [
    "***Exercise:*** \n",
    "\n",
    "As before, find the accuracy and recall of the model on the validation set, i.e. `X_val_proper`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "jqk5CSB3OvHl",
    "outputId": "33ffea09-2634-4dfd-d70f-7c7ce433e4eb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 0.8121431807884005\n",
      "recall = 0.1484848484848485\n"
     ]
    }
   ],
   "source": [
    "y_val_proper_pred = clf_rf.predict(X_val_proper)\n",
    "\n",
    "accuracy = accuracy_score(y_val_proper, y_val_proper_pred )\n",
    "recall = recall_score(y_val_proper, y_val_proper_pred )\n",
    "\n",
    "### END THE CODE ### \n",
    "\n",
    "print('accuracy = {}'.format(accuracy))\n",
    "print('recall = {}'.format(recall))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IG-QS_89OvHo"
   },
   "source": [
    "Expected output: \n",
    "\n",
    "<img src='https://github.com/nyp-sit/sdaai-staff-repo/blob/master/iti103/session-7(imbalanced-data)/images/acc_recall_score3.png?raw=1' />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mcgujKPMOvHp"
   },
   "source": [
    "This time round, we got only 15% recall. Let's see if this recall rate is more representative of the result on the test set. \n",
    "\n",
    "***Exercise:*** \n",
    "\n",
    "Find the accuracy and the recall of the model on the test set, i.e. `X_test`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "D5zbMK5KOvHq",
    "outputId": "61a5a30c-e638-4a6e-c450-27fd0a8d69d6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 0.8016475002038985\n",
      "recall = 0.14211663066954644\n"
     ]
    }
   ],
   "source": [
    "### START THE CODE ### \n",
    "y_test_pred = clf_rf.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_test_pred)\n",
    "recall = recall_score(y_test, y_test_pred)\n",
    "\n",
    "### END THE CODE ### \n",
    "\n",
    "print('accuracy = {}'.format(accuracy))\n",
    "print('recall = {}'.format(recall))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Jj1ym2fVOvHu"
   },
   "source": [
    "Expected output: \n",
    "\n",
    "<img src='https://github.com/nyp-sit/sdaai-staff-repo/blob/master/iti103/session-7(imbalanced-data)/images/acc_recall_score4.png?raw=1' />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qYkuhnyIOvHu"
   },
   "source": [
    "Now, we can see that the recall rate obtained from the cross validation set matches more closely the result from the test set, which is about 14% recall. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YZG0w03bOvHw"
   },
   "source": [
    "### 8. Oversampling when doing K-Fold \n",
    "\n",
    "If you are doing K-fold cross validation, below is the code to show you how to do the oversampling properly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 121
    },
    "colab_type": "code",
    "id": "hFwOe5hgOvHw",
    "outputId": "c729bf5d-9ac8-457c-d0e6-84200d848588"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score for 0 fold: 0.8018814061607895\n",
      "Recall score for 0 fold: 0.14240460763138948\n",
      "Accuracy score for 1 fold: 0.8001957532421631\n",
      "Recall score for 1 fold: 0.1375089992800576\n",
      "Accuracy score for 2 fold: 0.8020663404023926\n",
      "Recall score for 2 fold: 0.14398848092152627\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "skfolds = StratifiedKFold(n_splits=3, random_state=42)\n",
    "\n",
    "clf_rf = RandomForestClassifier(n_estimators=25, random_state=42)\n",
    "sm = SMOTE(sampling_strategy='minority',random_state=42) \n",
    "\n",
    "# We use enumerate() to return also the index position of the list so that we can print out the fold number\n",
    "for fold, (train_index, val_index) in enumerate(skfolds.split(X_train, y_train)):\n",
    "    #print(train_index, val_index)\n",
    "    X_train_fold = X_train.iloc[train_index]\n",
    "    y_train_fold = y_train.iloc[train_index]\n",
    "    X_val_fold = X_train.iloc[val_index]\n",
    "    y_val_fold = y_train.iloc[val_index]\n",
    "    X_train_fold_oversample, y_train_fold_oversample = sm.fit_sample(X_train_fold, y_train_fold)\n",
    "    clf_rf.fit(X_train_fold_oversample, y_train_fold_oversample)\n",
    "    y_val_fold_pred = clf_rf.predict(X_val_fold)\n",
    "    print('Accuracy score for {} fold: {}'.format(fold, accuracy_score(y_val_fold,y_val_fold_pred)))\n",
    "    print('Recall score for {} fold: {}'.format(fold, recall_score(y_val_fold, y_val_fold_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "njcQmRKOP06j"
   },
   "source": [
    "If you don't want to use data frame for the StratifiedKFold, and prefer to work with numpy array\n",
    "\n",
    "You can first convert the X_train and y_train to numpy array as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 121
    },
    "colab_type": "code",
    "id": "QZblkTYROvHz",
    "outputId": "1240c29c-8d6a-4b46-cb5a-bfe6a70e90c4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score for 0 fold: 0.8018814061607895\n",
      "Recall score for 0 fold: 0.14240460763138948\n",
      "Accuracy score for 1 fold: 0.8001957532421631\n",
      "Recall score for 1 fold: 0.1375089992800576\n",
      "Accuracy score for 2 fold: 0.8020663404023926\n",
      "Recall score for 2 fold: 0.14398848092152627\n"
     ]
    }
   ],
   "source": [
    "X_train_arr = X_train.values\n",
    "y_train_arr = y_train.values\n",
    "\n",
    "skfolds = StratifiedKFold(n_splits=3, random_state=42)\n",
    "\n",
    "clf_rf = RandomForestClassifier(n_estimators=25, random_state=42)\n",
    "sm = SMOTE(sampling_strategy='minority',random_state=42) \n",
    "\n",
    "# We use enumerate() to return also the index position of the list so that we can print out the fold number\n",
    "for fold, (train_index, val_index) in enumerate(skfolds.split(X_train_arr, y_train_arr)):\n",
    "    #print(train_index, val_index)\n",
    "    X_train_fold = X_train_arr[train_index]\n",
    "    y_train_fold = y_train_arr[train_index]\n",
    "    X_val_fold = X_train_arr[val_index]\n",
    "    y_val_fold = y_train_arr[val_index]\n",
    "    X_train_fold_oversample, y_train_fold_oversample = sm.fit_sample(X_train_fold, y_train_fold)\n",
    "    clf_rf.fit(X_train_fold_oversample, y_train_fold_oversample)\n",
    "    y_val_fold_pred = clf_rf.predict(X_val_fold)\n",
    "    print('Accuracy score for {} fold: {}'.format(fold, accuracy_score(y_val_fold,y_val_fold_pred)))\n",
    "    print('Recall score for {} fold: {}'.format(fold, recall_score(y_val_fold, y_val_fold_pred)))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Oversampling(Solution).ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
